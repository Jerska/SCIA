# Optimisation Convexe

*Cours du 10 février 2014*

## Présentation du prof
**Ruiz Manuel**

Thèse dans l'optimisation de la bouffe pour le bétail

Consultant en optimisation chez Arthelys
E-mail: manuel.ruiz@artelys.com
Skype: manuel.ruiz.artelys

## Objectifs

Comprendre les enjeux de l'**optimisation non linéaire** (théoriques et pratiques)

## Evaluation des compétences

- Soutenance par trinômes
- Développement d'une idée maeure du cours
- Ecriture d'une présentation permettant de convaincre qu'on a compris (Dessins, images, etc. mais **PAS DE FORMULE**)

## Deux outils utilisés

**AMPL** & **KNITRO**

## Introduction

5 questions :
- **Optimisation ?**
  Branche des mathématiques cherchant à analyser et à résoudre analytiquement ou numériquement les problèmes qui consistent à déterminer le meilleur élément d'un ensemble, au sens d'un critère quantitatif donné.
- **Convexe ?**
- Différentiable ?
- Conditions d'optimalité ?
- Théorie et application ?

Qu'est-ce qu'une fonction ?
Qu'est-ce que l'optimisation ?
Qu'est-ce que l'optimisation linéaire ?
Ex : Minimiser un problème qui répond à des critère.
- Contraintes :
  - Linéaires

Un problème d'optimisation connexe différentiable est un problème de minimisation d'une fonction convexe différentiable
sous contraintes définissant un domaine convexe exprimé à l'aide de.


## Espace vectoriel


Deux notations pour un vecteur colonne :

$$ x = \left[ \begin{array}{c} x\_1 \\\\ \dotsc \\\\ x\_n \end{array} \right] = [x\_i]\_{1 - n}$$
$$ \overline{x} . x = |x|^2 $$

Le produit scalaire usuel défini sur $E$ est noté :

$$&lt; x, y &gt; = x × y = x^T . y = \sum\limits\_{i = 1}^n (x\_i . y\_i) $$

Un ensemble convexe satisfait :

$$ \forall x \in E,\; \forall y \in E, \; \forall \lambda \in [0, 1], \; \lambda x + (1 - \lambda)y \in E $$

## Fonctions

Application de $E$ dans $\mathbb{R}$ qui, à tout élément $x \in E$ associe une unique valeur $f(x)$

- **Forme linéaire**, cas particulier où : $f(x) = a . x$

- **Forme affine**, cas particulier où : $f(x) = a . x + b$
  $$ A.x = n \implies \left\\\{ \begin{array}{} x\_0 \in E \text{ tq } A . x\_0 = b \\\\ v \in \text{Ker}(E) \text{ tq } x\_i = x\_0 + v\_i \end{array} \right. $$

- **Forme quadratique**, cas particulier où : $f(x) = x . A . x + b . x + c = &lt; x, A . x &gt; + b . x + x$

$f$ est **convexe** si elle est en dessous de ses cordes

## Les formes quadratiques

- À une transformation affine près, dans ce cours, les formes quadratiques seron de la forme :

$$ q(x) = x^T . M . x = &lt; x, Mx &gt; $$

  Il existe une matrice symétrique M.

- Toute matrice **_symétrique réelle_** admet :

  - Des valeurs propres et des vecteurs propres
  - Une base de vecteurs propres
  - Une expression de la forme $ P^T . DP$ avec $D = \text{diag}\Big(\text{Sp}(M)\Big)$

  **Remarques**:
  - ${M + M^T \over 2} = $ Symétrique
  - ${M - M^T \over 2} = $ Anti-symétrique
  - $$\begin{array}{rl}
    x^T . M.x = & x^T \left( {M + M^T \over 2} + {M - M^T \over 2}\right) . x \\\\
    = & x^T . S . x + x^T \left( {M - M^T \over 2} \right) . x \;\;\;\; \text{ avec } S = \text{Sym}(M) \\\\
    = & x^T . S . x + {1 \over 2}\left( x^T . M . x - x^T . M^T .x \right) \\\\
    = & x^T . S . x + {1 \over 2}(&lt; x, Mx &gt; - &lt; Mx, x &gt; ) \\\\
    = & x^T . S . x
    \end{array}$$

- En notant $y = P\_x$, l'expression de $x$ dans la nouvelle base
  $$ q(x) = \sum\limits\_{\lambda\_i \in \text{Sp}(M)} (\lambda\_i . y\_i^2)$$

- Une forme quadratiques est définie si et seulement si
  $$ q(x) = 0 \iff x = 0 $$

  NB : $x = 0 \implies q(x) = 0$ toujours vrai


- Si $q$ est définie, alors $M$ est inversible

- Une forme quadratique définie est définie positive ou définie négative
  - Preuve par l'absurde : $q(x\_+) > 0$ et $q(x\_-) < 0$
  - Utiliser $\varnothing: t \in [0, 1] \longrightarrow \varnothing(t) = (1 - t) . x\_- + t . x\_+$
  - $\varnothing(0) < 0$ et $\varnothing(1) > 0$, $\varnothing$ continue donc ... ?

- Le rang d'une forme quadratique est $n - \text{dim}(\text{Ker}(q))$
  - $n$ est la dimension de l'espace

- Pour étudier une forme quadratique, on étudie le spectre de la matrice associée.
  - Si \\( \exists (x, y) \; tq \; q(x)q(y) < 0 \\), alors $q$ n'est pas définie
  - Valeurs propres / Vecteurs propres
  - Racines du polynôme caractéristique : $x\_M (\lambda) = det(M - \lambda I)$

- Caractériser les formes quadratiques suivantes
  - \\( Q(x, y, z) = 2x² - 2y² - 6z² + 3xy - 4xz + 7yz \\)
    $$ M = \begin{pmatrix} 2 & \frac{3}{2} & -2 \\\\ \frac{3}{2} & -2 & \frac{7}{2} \\\\ -2 & \frac{7}{2} & 6 \end{pmatrix} $$

  - \\( Q(x, y, z) = 3x² + 3y² + 3z² + 2xy - 2xz + 2yz \\)
    $$ M = \begin{pmatrix}3 & 1 & -1 \\\\ 1 & 3 & 1 \\\\ -1 & 1 & 3 \end{pmatrix} $$

  - \\( Q(x, y, z, t) = xy + yz + zt + tx \\)
    $$ 2M = \begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \end{pmatrix}$$

  **Remarque**: \\( q(e\_i) = m\_{i,i} \\)

### Dérivées

- Le **gradient** est un vecteur formé de dérivées partielles
- Pour montrer qu'une application est différentiable, montrer qu'elle est de classe \\(C^1\\)
  - Déterminer l'expression de son gradient
  - Monter que le gradient est continu
- Exemples
  - Fonction linéaire
  - Forme quadratique, polynomiale

## Étude des points singuliers
- Quand elle existe la différentielle permet de faire un approximation à l'ordre 1 d'une fonction
- La différentielle est une application linéaire
- Les points sinfuliers sont les points où la différentielle est l'application nulle
- Déterminer les points singuliers se fait en résolvant un système d'équation posé en annulant le gradient
- L'étude de la forme quadratique associée à la matrice hessienne permet de dire si l'on a un extremum local (min ou max) ou non

### Exemple
$$\begin{array}{rl}
f(x, y) = & x^4 + y^4 - 2(x - y)^2  \\\\
= & x^4 + y^4 - 2x^2 + 4xy - 2y^2 \\\\
\triangledown f(x, y) = & \left( \begin{array}{} 4x^3 - 4x + 4y \\\\ 4y^3 - 4y + 4x \end{array} \right) \\\\
\text{On cherche } \;\; \triangledown f(x, y) = & \left( \begin{array}{} 0 \\\\ 0 \end{array} \right) \\\\
\iff & \left\\\{ \begin{array}{} 4x^3 - 4x + 4y = 0 \\\\ 4y^3 - 4y + 4x = 0 \end{array} \right. \\\\
\iff & \left\\\{ \begin{array}{} x^3 - x = -y \\\\ y^3 - y = -x \end{array} \right. \\\\
\iff & \left\\\{ \begin{array}{} x = y - y^3 \\\\ y = y - y^3 - \left( y - y^3 \right)^3  \end{array} \right. \\\\
\text{Cherchons la matrice hessienne } \;\; \triangledown^2f(x, y) = & \begin{pmatrix} {\partial \triangledown f(x, y)[0] \over \partial x} & {\partial \triangledown f(x, y)[0] \over \partial y} \\\\ {\partial \triangledown f(x, y)[1] \over \partial x} & {\partial \triangledown f(x, y)[1] \over \partial y} \\\\\end{pmatrix} \\\\
= & \begin{pmatrix} 12x^2 - 4 & 4 \\\\ 4 & 12y^2 - 4 \end{pmatrix}
\end{array}$$

>On détermine les points singuliers avec l'expression du gradient (On cherche $\triangledown f(x, y) = 0$).
>On cherche les valeurs propres de la hessienne ($\triangledown^2 f(x, y)$) pour chacun des points singuliers. (Sur une matrice diagonale, les valeurs propres sont les valeurs de la diagonale)
>Si elles sont toutes négatives, on a un maximum local.
>Si elles sont toutes positives, on a un minimum local.
>Sinon, c'est non défini.

** Remarque **
Une forme quadratique dont certaines valeurs propres de la hessienne sont positives et négatives est non définie, pourquoi ?
$q$ est définie : $q(x) = 0 \iff x = 0$
Si $\left\\\{ \begin{array}{} \exists X\_0 \text{ tq } q(X\_0) > 0 \\\\ \exists Y\_0 \text{ tq } q(Y\_0) < 0\end{array}\right.$, prenons  $f : \lambda \in [0, 1] \longmapsto q(\lambda X\_0 + (1 - \lambda) Y\_0)$.
$f(0) = \underset{> 0}{q(Y\_0)}$ et $f(1) = \underset{< 0}{q(X\_0)}$ $\implies \exists \lambda\_0 \text{ tq } f(\lambda\_0) = 0$
Soit $Z\_0 = \lambda\_0 X\_0 + (1 - \lambda\_0) Y\_O, q(Z\_0) = q(\lambda\_0) = 0$
$Z\_0 \implies X\_0$ et $Y\_0$ sont colinéaires ($X\_0 = \alpha Y\_0$).
$\underset{< 0}{q(X\_0)} = q(\alpha Y\_0) = \underset{\geq 0}{\alpha^2} . \underset{\gt 0}{q(Y\_0)}$. **Impossible !**

## Méthode de newton

L'idée de la méthode de Newton est de converger vers $0$.

## Exercices

1. - **Qu'est-ce que la différentielle d'une fonction et à quoi sert elle ?**
     La différentielle est une application linéaire pour faire une approximation linéaire en un point, et elle est définie par le gradient autour du point.
     Elle vaut : $dfa(x) = \triangledown f(a)^T . x = 2 . a^T . x$
   - **Calculer la différentielle de $f : x \in \mathbb{R}^k \longmapsto \parallel x \parallel^2$ **
     $$\begin{array}{rl}
     \parallel x \parallel^2 = & \lt x, x \gt \; = \; x^T . x = \; \sum\limits\_{i = 1}^n x\_i^2 \\\\
     \triangledown f(x) = & \begin{pmatrix} {\partial f(x) \over \partial x\_1} \\\\ ... \\\\ {\partial f(x) \over \partial x\_n} \end{pmatrix} = \; \begin{pmatrix} 2x\_1 \\\\ ... \\\\ 2 x\_n \end{pmatrix} = \; 2x \\\\
     \tilde{fa}(x) = & f(a) + \triangledown f(a)^T(x - a) \\\\
     = & \parallel a \parallel^2 + 2 a^T(x - a) \\\\
     = & \parallel a \parallel^2 + 2 a^T x - 2 a^T a \\\\
     = & 2 a^T x - \parallel a \parallel^2
     \end{array}$$

2. - **Qu'est-ce que l'algo de Newton ?**
     L'aglorithme de Newton est un algorithme permettant d'approximer une fonction en $0$.
     On prend $F : \mathbb{R}^n \longmapsto \mathbb{R}^k$. $ F = \left\\\{ \begin{array}{} F\_1(x) \\\\ ... \\\\ F\_k(x) \end{array} \right. $
     On cherche $x \in \mathbb{R}^n \text{ tq } F(x) = 0$.
   - **Quelles sont ses grandes lignes ?**
     - *Initialisation*
       On prend un $x\_0$
     - *Linéarisation autour de $x\_k$*
       $\tilde{F}\_k(x) = F(x\_k) + J(x\_k)(x - x\_k)$
       $J$ est la *Jacobienne*
       $$J(x) = \left( \begin{array}{} \triangledown F\_1(x)^T \\\\ ... \\\\ \triangledown F\_k(x)^T \end{array} \right)$$
       $x\_{k + 1}$ est la solution de $F(x\_k) = 0$
   - **Exemple**
     $$ \left\\\{ \begin{array}{} x^2 + y^2 - 1 \\\\ x - y \end{array} \right. $$
     $$\begin{array}{rl}
       \tilde{F}\_k \begin{pmatrix} 1 \\\\ 1\end{pmatrix} = & \begin{pmatrix} 1 \\\\ 0 \end{pmatrix} + \begin{pmatrix} 2 & 2 \\\\ 1 & -1 \end{pmatrix} \begin{pmatrix} x - 1  \\\\ y - 1 \end{pmatrix} \\\\
       = & \begin{pmatrix} 2x + 2y -3\\\\ x - y \end{pmatrix}
     \end{array}$$

3. - **Qu'est-ce que les conditions d'optimalité ?**
     C'est une méthodologie qui à partir d'un problème d'optimisation donne un système d'équation.
     Ex: $\underset{x \in \mathbb{R}^n}{\text{min }} c^T x$ avec $Ax = a$ et $x \ge 0 \iff -x \le {0}$.
     On a comme règles :
     - $\triangledown f(x) = \sum\limits\_{i \in I, E} \lambda\_i \triangledown h\_i x$ ($I$ : contraintes d'inégalité et $E$ : contraintes d'égalité)
     - Si $h\_i(x) . \lambda\_i = 0$, alors $i \in I$
     - Si $\lambda\_i \leq 0$, alors $i \in I$
     - Si $\lambda\_i \in \mathbb{R}$, alors $i \in E$

     On appelle $h\_i$ chaque contrainte.

     La condition d'optimalité transforme
     $$\left\\\{\begin{array}{rl} & \text{min} f(x) \\\\
       i \in E & h\_i(x) = 0 \\\\
       i \in I & h\_i(x) \le 0 \\\\
       & x \in \mathbb{R}^n
     \end{array}\right.
     \longmapsto
     \left\\\{\begin{array}{rl} \triangledown f & \sum\limits\_{i} \lambda\_i \triangledown h\_i (x)  \\\\
       i \in E & h\_i(x) = 0 \text{ et } \lambda\_i \in \mathbb{R} \\\\
       i \in I & \lambda\_i h\_i(x) = 0 \text{ et } \lambda\_i \le 0 \\\\
       & x \in \mathbb{R}^n
     \end{array}\right.
     $$

     En l'appliquant à la programmation linéaire, on obtient :
     - $c = \lambda A^T - \mu \iff c - \lambda A^T = -\mu$
     - $\mu \le 0 \iff c - \lambda A^T \ge 0$
     - $\lambda \in \mathbb{R}^n \iff (x > 0 \implies \mu = 0)$
     - $\mu\_i . (- x\_i) = 0$ ($i \in [1, n]$) $ \iff (\mu \lt 0 \implies x = 0)$

4. - **Qu'est-ce qu'un point singulier d'une fonction $f: \mathbb{R}^n \; \longmapsto \; \mathbb{R}$**
     Un point où la différentielle de la fonction s'annule.
   - **À quoi ça sert ?**
     Ça sert à trouver des optimums locaux. (**Attention !** tous les points singuliers ne sont pas des optimums locaux)
   - **Étudier en fonction de $\alpha \in \mathbb{R}$ ceux de $f\_{\alpha}(x, y, z) \longmapsto \alpha x^2 + y^2 + z^2 - 10 xy$**
     $$\begin{array}{rl}
      f\_{\alpha}(x, y, z) \longmapsto & \alpha x^2 + y^2 + z^2 - 10 xy \\\\
      \triangledown f\_{\alpha}(x, y, z) = & \begin{pmatrix}
      2 \alpha x - 10y \\\\
      2y - 10x \\\\
      2z
      \end{pmatrix} \\\\
      \text{On cherche } \;\; \triangledown f\_{\alpha}(x, y, z) = & \begin{pmatrix}
      0 \\\\
      0 \\\\
      0 \\\\
      \end{pmatrix} \\\\
      \iff & \left\\\{ \begin{array}{}
      2 \alpha x - 10y = 0\\\\
      2y - 10x = 0\\\\
      2z = 0
      \end{array}\right. \\\\
      \iff & \left\\\{ \begin{array}{}
      x = {1 \over \alpha - 25}\\\\
      y = 5x\\\\
      z = 0
      \end{array}\right. \;\;\; \text{On a donc } \alpha \ne 25 \\\\
      \iff & \left\\\{ \begin{array}{}
      x = {1 \over \alpha - 25} \\\\
      y = {5 \over \alpha - 25} \\\\
      z = 0
      \end{array}\right. \\\\
      \triangledown^2 f\_{\alpha}(x, y, z) = & \begin{pmatrix}
      2\alpha & -10 & 0 \\\\
      -10 & 2 & 0 \\\\
      0 & 0 & 2
      \end{pmatrix} \\\\
      \Pi (\lambda) = & (2 - \lambda).((2\alpha - \lambda)(2 - \lambda) - 100) \\\\
      = & (2 - \lambda)(\lambda^2 - 2 . (\alpha + 1) \lambda + 4 \alpha - 100) \\\\
      \Delta = & - 4\alpha^2 - 8\alpha - 4 - 8 \alpha - 800 \\\\
      \text{Valeurs propres de } \Pi (\lambda) = & \left\\\{ \begin{array}{}
      \Pi\_1 = 2 \\\\
      \Pi\_2 = \\\\
      \Pi\_3 = 
      \end{array} \right.
     \end{array}$$
     Si les valeurs propres de la matrice hessienne sont toutes positives/négatives, alors la matrice est définie positive / négative, d'où le point singulier est un minimum / maximum.
     Si l'une des valeurs propres est nulle ou qu'elles n'ont pas toute le même signe, la matrice n'est pas définie, donc on ne peux pas conclure.
     **Attention !** Si on a un 0 sur la diagonale, on a pas une valeur propre.
4. - **Écrire les condition d'optimalité de :**
     $$x \in \mathbb{R}^n \text{min }f(x) x\_i \le 0$$
     $$\left\\\{ \begin{array}{}
      \triangledown f(x) = \mu \\\\
      \mu\_i x\_i = 0 \\\\
      \mu\_i \le 0
     \end{array}\right. $$
   - **Écrire les condition d'optimalité de :**
     $$\text{min }f(x) - p . \ln(-x)$$
     $$\left\\\{ \begin{array}{}
      \triangledown f(x) -p . {1 \over \sum\limits\_i x\_i} . e = 0\\\\
     \end{array}\right. $$
     On peut en fait passer de l'une à l'autre :
     $$\begin{array}{rl}
      & \left\\\{ \begin{array}{}
       \text{min } f(x) \\\\
       g(x) \le 0
      \end{array}\right. \\\\
      & \left\\\{ \begin{array}{}
       \triangledown f(x) = \mu \triangledown g(x) \\\\
       \mu g(x) = 0 \\\\
       \mu \le 0
      \end{array}\right. \\\\
      \text{On passe en réels} &
      \left\\\{ \begin{array}{}
       f^\prime (x) = \mu g^\prime(x) \\\\
       \mu g(x) = 0 \implies \mu g(x) \ge 0 \\\\
       \mu \le 0
      \end{array}\right. \\\\
      & \left\\\{ \begin{array}{}
       f^\prime (x) = \mu g^\prime(x) \\\\
       \mu g(x) = p \:\:\; p \ge 0 \\\\
       \mu \le 0
      \end{array}\right. \\\\
      & \left\\\{ \begin{array}{}
       f^\prime (x) - p {g^\prime(x) \over g(x)} = 0 \\\\
       p \le 0
      \end{array}\right.
     \end{array}$$

     **Cours :**
     On a une fonction $\text{min } f(x)$ avec des contraintes d'inégalité $g(x) \le 0 \;\forall i \in I$
     On ajoute $(\mu\_i) \forall i \in I$
     Ce qui donne :
     $$\left \\\{ \begin{array}{}
     \triangledown f(x) = \sum\limits\_{i \in I} \mu\_i \triangledown g\_i (x) \\\\
     \mu\_i g\_i (x) = 0 \\\\
     \mu\_i \le 0
     \end{array} \right.$$
     Rajouter des contraintes d'égalite provoque ce changement : $\triangledown f(x) = \sum\limits\_{i \in I} \mu\_i \triangledown g\_i (x) + \sum\limits\_{j \in E} \lambda\_j \triangledown h\_i (x)$
   - **Étudier le cas où $p \longrightarrow 0$**
     Ça revient à s'apporcher des points singuliers.


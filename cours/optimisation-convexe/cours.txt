# Optimisation Convexe

*Cours du 10 février 2014*

## Présentation du prof
**Ruiz Manuel**

Thèse dans l'optimisation de la bouffe pour le bétail

Consultant en optimisation chez Arthelys
E-mail: manuel.ruiz@artelys.com
Skype: manuel.ruiz.artelys

## Objectifs

Comprendre les enjeux de l'**optimisation non linéaire** (théoriques et pratiques)

## Evaluation des compétences

- Soutenance par trinômes
- Développement d'une idée maeure du cours
- Ecriture d'une présentation permettant de convaincre qu'on a compris (Dessins, images, etc. mais **PAS DE FORMULE**)

## Deux outils utilisés

**AMPL** & **KNITRO**

## Introduction

5 questions :
- **Optimisation ?**
  Branche des mathématiques cherchant à analyser et à résoudre analytiquement ou numériquement les problèmes qui consistent à déterminer le meilleur élément d'un ensemble, au sens d'un critère quantitatif donné.
- **Convexe ?**
- Différentiable ?
- Conditions d'optimalité ?
- Théorie et application ?

Qu'est-ce qu'une fonction ?
Qu'est-ce que l'optimisation ?
Qu'est-ce que l'optimisation linéaire ?
Ex : Minimiser un problème qui répond à des critère.
- Contraintes :
  - Linéaires

Un problème d'optimisation connexe différentiable est un problème de minimisation d'une fonction convexe différentiable
sous contraintes définissant un domaine convexe exprimé à l'aide de.


## Espace vectoriel


Deux notations pour un vecteur colonne :

$$ x = \left[ \begin{array}{c} x\_1 \\\\ \dotsc \\\\ x\_n \end{array} \right] = [x\_i]\_{1 - n}$$
$$ \overline{x} . x = |x|^2 $$

Le produit scalaire usuel défini sur $E$ est noté :

$$&lt; x, y &gt; = x × y = x^T . y = \sum\limits\_{i = 1}^n (x\_i . y\_i) $$

Un ensemble convexe satisfait :

$$ \forall x \in E,\; \forall y \in E, \; \forall \lambda \in [0, 1], \; \lambda x + (1 - \lambda)y \in E $$

## Fonctions

Application de $E$ dans $\mathbb{R}$ qui, à tout élément $x \in E$ associe une unique valeur $f(x)$

- **Forme linéaire**, cas particulier où : $f(x) = a . x$

- **Forme affine**, cas particulier où : $f(x) = a . x + b$
  $$ A.x = n \implies \left\\\{ \begin{array}{} x\_0 \in E \text{ tq } A . x\_0 = b \\\\ v \in \text{Ker}(E) \text{ tq } x\_i = x\_0 + v\_i \end{array} \right. $$

- **Forme quadratique**, cas particulier où : $f(x) = x . A . x + b . x + c = &lt; x, A . x &gt; + b . x + x$

$f$ est **convexe** si elle est en dessous de ses cordes

## Les formes quadratiques

- À une transformation affine près, dans ce cours, les formes quadratiques seron de la forme :

$$ q(x) = x^T . M . x = &lt; x, Mx &gt; $$

  Il existe une matrice symétrique M.

- Toute matrice **_symétrique réelle_** admet :

  - Des valeurs propres et des vecteurs propres
  - Une base de vecteurs propres
  - Une expression de la forme $ P^T . DP$ avec $D = \text{diag}\Big(\text{Sp}(M)\Big)$

  **Remarques**:
  - ${M + M^T \over 2} = $ Symétrique
  - ${M - M^T \over 2} = $ Anti-symétrique
  - $$\begin{array}{rl}
    x^T . M.x = & x^T \left( {M + M^T \over 2} + {M - M^T \over 2}\right) . x \\\\
    = & x^T . S . x + x^T \left( {M - M^T \over 2} \right) . x \;\;\;\; \text{ avec } S = \text{Sym}(M) \\\\
    = & x^T . S . x + {1 \over 2}\left( x^T . M . x - x^T . M^T .x \right) \\\\
    = & x^T . S . x + {1 \over 2}(&lt; x, Mx &gt; - &lt; Mx, x &gt; ) \\\\
    = & x^T . S . x
    \end{array}$$

- En notant $y = P\_x$, l'expression de $x$ dans la nouvelle base
  $$ q(x) = \sum\limits\_{\lambda\_i \in \text{Sp}(M)} (\lambda\_i . y\_i^2)$$

- Une forme quadratiques est définie si et seulement si
  $$ q(x) = 0 \iff x = 0 $$

  NB : $x = 0 \implies q(x) = 0$ toujours vrai


- Si $q$ est définie, alors $M$ est inversible

- Une forme quadratique définie est définie positive ou définie négative
  - Preuve par l'absurde : $q(x\_+) > 0$ et $q(x\_-) < 0$
  - Utiliser $\varnothing: t \in [0, 1] \longrightarrow \varnothing(t) = (1 - t) . x\_- + t . x\_+$
  - $\varnothing(0) < 0$ et $\varnothing(1) > 0$, $\varnothing$ continue donc ... ?

- Le rang d'une forme quadratique est $n - \text{dim}(\text{Ker}(q))$
  - $n$ est la dimension de l'espace

- Pour étudier une forme quadratique, on étudie le spectre de la matrice associée.
  - Si \\( \exists (x, y) \; tq \; q(x)q(y) < 0 \\), alors $q$ n'est pas définie
  - Valeurs propres / Vecteurs propres
  - Racines du polynôme caractéristique : $x\_M (\lambda) = det(M - \lambda I)$

- Caractériser les formes quadratiques suivantes
  - \\( Q(x, y, z) = 2x² - 2y² - 6z² + 3xy - 4xz + 7yz \\)
    $$ M = \begin{pmatrix} 2 & \frac{3}{2} & -2 \\\\ \frac{3}{2} & -2 & \frac{7}{2} \\\\ -2 & \frac{7}{2} & 6 \end{pmatrix} $$

  - \\( Q(x, y, z) = 3x² + 3y² + 3z² + 2xy - 2xz + 2yz \\)
    $$ M = \begin{pmatrix}3 & 1 & -1 \\\\ 1 & 3 & 1 \\\\ -1 & 1 & 3 \end{pmatrix} $$

  - \\( Q(x, y, z, t) = xy + yz + zt + tx \\)
    $$ 2M = \begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \end{pmatrix}$$

  **Remarque**: \\( q(e\_i) = m\_{i,i} \\)

### Dérivées

- Le **gradient** est un vecteur formé de dérivées partielles
- Pour montrer qu'une application est différentiable, montrer qu'elle est de classe \\(C^1\\)
  - Déterminer l'expression de son gradient
  - Monter que le gradient est continu
- Exemples
  - Fonction linéaire
  - Forme quadratique, polynomiale

## Étude des points singuliers
- Quand elle existe la différentielle permet de faire un approximation à l'ordre 1 d'une fonction
- La différentielle est une application linéaire
- Les points sinfuliers sont les points où la différentielle est l'application nulle
- Déterminer les points singuliers se fait en résolvant un système d'équation posé en annulant le gradient
- L'étude de la forme quadratique associée à la matrice hessienne permet de dire si l'on a un extremum local (min ou max) ou non

### Exemple
$$\begin{array}{rl}
f(x, y) = & x^4 + y^4 - 2(x - y)^2  \\\\
= & x^4 + y^4 - 2x^2 + 4xy - 2y^2 \\\\
\triangledown f(x, y) = & \left( \begin{array}{} 4x^3 - 4x + 4y \\\\ 4y^3 - 4y + 4x \end{array} \right) \\\\
\text{On cherche } \;\; \triangledown f(x, y) = & \left( \begin{array}{} 0 \\\\ 0 \end{array} \right) \\\\
\iff & \left\\\{ \begin{array}{} 4x^3 - 4x + 4y = 0 \\\\ 4y^3 - 4y + 4x = 0 \end{array} \right. \\\\
\iff & \left\\\{ \begin{array}{} x^3 - x = -y \\\\ y^3 - y = -x \end{array} \right. \\\\
\iff & \left\\\{ \begin{array}{} x = y - y^3 \\\\ y = y - y^3 - \left( y - y^3 \right)^3  \end{array} \right. \\\\
\text{Cherchons la matrice hessienne } \;\; \triangledown^2f(x, y) = & \begin{pmatrix} {\partial \triangledown f(x, y)[0] \over \partial x} & {\partial \triangledown f(x, y)[0] \over \partial y} \\\\ {\partial \triangledown f(x, y)[1] \over \partial x} & {\partial \triangledown f(x, y)[1] \over \partial y} \\\\\end{pmatrix} \\\\
= & \begin{pmatrix} 12x^2 - 4 & 4 \\\\ 4 & 12y^2 - 4 \end{pmatrix}
\end{array}$$

>On détermine les points singuliers avec l'expression du gradient (On cherche $\triangledown f(x, y) = 0$).
>On cherche les valeurs propres de la hessienne ($\triangledown^2 f(x, y)$) pour chacun des points singuliers. (Sur une matrice diagonale, les valeurs propres sont les valeurs de la diagonale)
>Si elles sont toutes négatives, on a un maximum local.
>Si elles sont toutes positives, on a un minimum local.
>Sinon, c'est non défini.

** Remarque **
Une forme quadratique dont certaines valeurs propres de la hessienne sont positives et négatives est non définie, pourquoi ?
$q$ est définie : $q(x) = 0 \iff x = 0$
Si $\left\\\{ \begin{array}{} \exists X\_0 \text{ tq } q(X\_0) > 0 \\\\ \exists Y\_0 \text{ tq } q(Y\_0) < 0\end{array}\right.$, prenons  $f : \lambda \in [0, 1] \longmapsto q(\lambda X\_0 + (1 - \lambda) Y\_0)$.
$f(0) = \underset{> 0}{q(Y\_0)}$ et $f(1) = \underset{< 0}{q(X\_0)}$ $\implies \exists \lambda\_0 \text{ tq } f(\lambda\_0) = 0$
Soit $Z\_0 = \lambda\_0 X\_0 + (1 - \lambda\_0) Y\_O, q(Z\_0) = q(\lambda\_0) = 0$
$Z\_0 \implies X\_0$ et $Y\_0$ sont colinéaires ($X\_0 = \alpha Y\_0$).
$\underset{< 0}{q(X\_0)} = q(\alpha Y\_0) = \underset{\geq 0}{\alpha^2} . \underset{\gt 0}{q(Y\_0)}$. **Impossible !**

## Méthode de newton

L'idée de la méthode de Newton est de converger vers $0$.

## Exercices

1. - **Qu'est-ce que la différentielle d'une fonction et à quoi sert elle ?**
     La différentielle est une application linéaire pour faire une approximation linéaire en un point, et elle est définie par le gradient autour du point.
     Elle vaut : $dfa(x) = \triangledown f(a)^T . x = 2 . a^T . x$
   - **Calculer la différentielle de $f : x \in \mathbb{R}^k \longmapsto \parallel x \parallel^2$ **
     $$\begin{array}{rl}
     \parallel x \parallel^2 = & \lt x, x \gt \; = \; x^T . x = \; \sum\limits\_{i = 1}^n x\_i^2 \\\\
     \triangledown f(x) = & \begin{pmatrix} {\partial f(x) \over \partial x\_1} \\\\ ... \\\\ {\partial f(x) \over \partial x\_n} \end{pmatrix} = \; \begin{pmatrix} 2x\_1 \\\\ ... \\\\ 2 x\_n \end{pmatrix} = \; 2x \\\\
     \tilde{fa}(x) = & f(a) + \triangledown f(a)^T(x - a) \\\\
     = & \parallel a \parallel^2 + 2 a^T(x - a) \\\\
     = & \parallel a \parallel^2 + 2 a^T x - 2 a^T a \\\\
     = & 2 a^T x - \parallel a \parallel^2
     \end{array}$$

2. - **Qu'est-ce que l'algo de Newton ?**
     L'aglorithme de Newton est un algorithme permettant d'approximer une fonction en $0$.
     On prend $F : \mathbb{R}^n \longmapsto \mathbb{R}^k$. $ F = \left\\\{ \begin{array}{} F\_1(x) \\\\ ... \\\\ F\_k(x) \end{array} \right. $
     On cherche $x \in \mathbb{R}^n \text{ tq } F(x) = 0$.
   - **Quelles sont ses grandes lignes ?**
     - *Initialisation*
       On prend un $x\_0$
     - *Linéarisation autour de $x\_k$*
       $\tilde{F}\_k(x) = F(x\_k) + J(x\_k)(x - x\_k)$
       $J$ est la *Jacobienne*
       $$J(x) = \left( \begin{array}{} \triangledown F\_1(x)^T \\\\ ... \\\\ \triangledown F\_k(x)^T \end{array} \right)$$
       $x\_{k + 1}$ est la solution de $F(x\_k) = 0$
   - **Exemple**
     $$\left\\\{ \begin{array}{} x^2 + y^2 = 1 \\\\ x - y = 0 \end{array} \right.$$
     $$\begin{array}{rl}
       \tilde{F}\_k \begin{pmatrix} 1 \\\\ 1\end{pmatrix} = & \begin{pmatrix} 1 \\\\ 0 \end{pmatrix} + \begin{pmatrix} 2 & 2 \\\\ 1 & -1 \end{pmatrix} \begin{pmatrix} x - 1  \\\\ y - 1 \end{pmatrix} \\\\
       = & \begin{pmatrix} 2x + 2y -3 \\\\ x - y \end{pmatrix}
     \end{array}$$

3. - **Qu'est-ce que les conditions d'optimalité ?**
     C'est une méthodologie qui à partir d'un problème d'optimisation donne un système d'équation.
     Ex: $\underset{x \in \mathbb{R}^n}{\text{min }} c^T x$ avec $Ax = a$ et $x \ge 0 \iff -x \le {0}$.
     On a comme règles :
     - $\triangledown f(x) = \sum\limits\_{i \in I, E} \lambda\_i \triangledown h\_i x$ ($I$ : contraintes d'inégalité et $E$ : contraintes d'égalité)
     - Si $h\_i(x) . \lambda\_i = 0$, alors $i \in I$
     - Si $\lambda\_i \leq 0$, alors $i \in I$
     - Si $\lambda\_i \in \mathbb{R}$, alors $i \in E$

     On appelle $h\_i$ chaque contrainte.

     La condition d'optimalité transforme
     $$\left\\\{\begin{array}{rl} & \text{min} f(x) \\\\
       i \in E & h\_i(x) = 0 \\\\
       i \in I & h\_i(x) \le 0 \\\\
       & x \in \mathbb{R}^n
     \end{array}\right.
     \longmapsto
     \left\\\{\begin{array}{rl} \triangledown f & \sum\limits\_{i} \lambda\_i \triangledown h\_i (x)  \\\\
       i \in E & h\_i(x) = 0 \text{ et } \lambda\_i \in \mathbb{R} \\\\
       i \in I & \lambda\_i h\_i(x) = 0 \text{ et } \lambda\_i \le 0 \\\\
       & x \in \mathbb{R}^n
     \end{array}\right.
     $$

     En l'appliquant à la programmation linéaire, on obtient :
     - $c = \lambda A^T - \mu \iff c - \lambda A^T = -\mu$
     - $\mu \le 0 \iff c - \lambda A^T \ge 0$
     - $\lambda \in \mathbb{R}^n \iff (x > 0 \implies \mu = 0)$
     - $\mu\_i . (- x\_i) = 0$ ($i \in [1, n]$) $ \iff (\mu \lt 0 \implies x = 0)$
